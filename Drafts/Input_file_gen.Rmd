---
title: "Input file generation"
author: "Paolo Colombo"
date: "20/4/2021"
output: html_document
---

# Notes

* (in Big Reservoirs load and visualization) Pirabibu, Sità Cedro and Banabuiu reservoirs don't have a capacity associated to them in the shapefile. Which is the unit measure of the capacity in both shapefiles? Look online to find the capacities.
* (in Computation of the storage capacities) The area-volume relationship used seems to provide small volumes, check if it is correct.
* (in Reservoir classification by size) Are there standard classes to use to distinguish the different small reservoirs? **in Krol 2011** I found a reference to the classes but not to their boundaries
* (in Computation of the storage capacities) The file from Germano doesn't have the area information since the shapefile is a point shapefile. _We have to obtain this data in order to use the shapefile!_
* (in Time series update) Where should I download the data? I need georeferenced data to be able to create that kind of file (rows: days, columns: rain intensity for each SubbasinID)
* Subbasin 134 ends up in Subbasin 121 which is not defined! How to solve this?
* The number of the reservoirs in the different classes are not the same as the file provided by George and Alexandre. It may be that the coefficients change depending on the reservoir area (1), or it may depend on the classes they defined to divide the reservoirs (2). 1 > Check if this is true and then find the coefficients 2 > Ask them what did the do

# Files that have to be updated

**Just cut them around the Banabuiu basin**

* Hillslope/hymo.dat
* Hillslope/rainy_season.dat
* Hillslope/soil.dat
* Hillslope/soil_vegetation.dat
* Hillslope/soter.dat
* Hillslope/terrain.dat
* Hillslope/vegetation.dat

_all these can be generated through lumpR_

**Update them**

Parameters

* (lumpR) River/routing.dat         _done_ by "cutting"
* (lumpR) River/response.dat        _done_ by "cutting"
* Reservoir/lake.dat                _done_
* Reservoir/lake_maxvol.dat         _done_ by "cutting"
* Reservoir/lake_number.dat         _done_ **NEEDS TO BE CHECKED**
* (lumpR) Reservoir/reservoir.dat   _done_ by "cutting"
* Reservoir/cav.dat                 _done_ by "cutting"
* Reservoir/exttranspo_168_res.dat  _done_ by "cutting"

Time series

* Time_series/extraterrestrail_radiation.dat
* Time_series/humidity.dat
* Time_series/radiation.dat
* Time_series/rain_daily.dat
* Time_series/temperature.dat

**New optional files**

* Others/**calibration.dat**
* Reservoir/lake_frarea.dat
* Reservoir/**lake_year.dat**   (specification of changes in the number of reservoirs in the size classes)

**Decide what to do with these**

* Input/maxdim.dat
* Others/scaling_factor.dat
* Input/outfiles.dat


# Things to do on QGIS

- Associate to each reservoir the sub-basin ID (create a new column) _done_
- 

# Libraries and functions

```{r libraries}
setwd("C:/Users/Utente/OneDrive - Politecnico di Milano/Backup PC/Uni/Thesis/Analysis")

source("Libraries.R")
source("Functions.R")
```

# Load and visualization

Before importing the data here, to each shapefile a new column containing the SubbasinID corresponding to the objects (the reservoirs) has been added via QGIS

## Subbasins load and visualization

```{r subbasins.shp}
path<-"C:/Thesis_fortran/WASA/shapefile/Banabuiu"
subbasins<-st_read(paste0(path,"/subbasins_cut.shp"))
subbasins_plot<-ggplot()+
            geom_sf(data = subbasins)+
            ggtitle("Subbasins in Banabuiu basin - Mamede file")+
            coord_sf()
subbasins_plot

#subbasins$SubbasinID contains all the Subbasin IDs in the Banabuiu basin

```

## HDRN load and visualization

```{r HDRN1 load}
#Shapefile provided by Mamede
path<-"C:/Thesis_fortran/WASA/shapefile/Banabuiu"
HDRN1<-st_read(paste0(path,"/smalldams_cut_ref.shp"))
HDRN1_plot<-ggplot()+
            geom_sf(data = HDRN1)+
            ggtitle("Small reservoirs in Banabuiu basin - Mamede file")+
            coord_sf()

nHDRN1<-length(HDRN1$Area__m2_) #1381 small reservoirs

HDRN1[which(is.na(HDRN1$SubbasinID)),]
#check in QGIS if there are geometries that need to be fixed
#and redo the SubbasinID association

```

```{r HDRN2 load}
#Shapefile provided by Germano
path<-"C:/Thesis_fortran/WASA/shapefile/Banabuiu_shapefile/reserv_banabuiu.shp"
HDRN2<-st_read(path)
HDRN2_plot<-ggplot()+
            geom_sf(data = HDRN2)+
            ggtitle("Small reservoirs in Banabuiu basin - Germano file")+
            coord_sf()

nHDRN2<-length(HDRN2$geometry) #17322 reservoirs
```

```{r HDRN visual comparison}
#Visual comparison between the two shapefiles
#install.packages("gridExtra")

grid.arrange(HDRN1_plot,HDRN2_plot,ncol=2)
```

## Big reservoirs load and visualization

```{r mainI, mainII}
setwd("C:/Thesis_fortran/WASA/shapefile/Banabuiu")

main_resI<-st_read("mainreservoirsI_cut_ref.shp")
main_resI_plot<-ggplot()+
                geom_sf(data = main_resI)+
                ggtitle("Main reservoirs in Banabuiu basin - I")+
                coord_sf()
main_resI_plot

#summary(main_resI)
main_resI[which(is.na(main_resI$SubbasinID)),]
sum(is.na(main_resI$SubbasinID))
#no NA generated in the SubbasinID association

main_resII<-st_read("mainreservoirsII_cut_ref.shp")
main_resII_plot<-ggplot()+
                geom_sf(data = main_resII)+
                ggtitle("Main reservoirs in Banabuiu basin - II")+
                coord_sf()
main_resII_plot

#summary(main_resII)
main_resI[which(is.na(main_resI$SubbasinID)),]
sum(is.na(main_resI$SubbasinID))
```

```{r adjust (to do!)}
#Adjust the two dataframes to have only name, Subbasin ID and capacity
#Then put them togheter


```

# lake_number.dat

## Computation of the storage capacities

From the area of the geometrical elements, obtain the storage capacity of the reservoirs. The storage capacity can be obtained from the reservoir area through Molle area-volume relationship.

The Molle area-volume relationship here used and its parameters are explained in [Mamede et al., 2018, Eq. 9][1]

```{r Molle relationship}
# Molle area-volume relationship
#Volume = k*(Area/(a*k))^(a/(a-1))
#Area = a*k*(Volume/k)^((a-1)/a)

k <- damk_Molle <- 1500
a <- alpha_Molle <- 2.7

HDRN1$capacity<-k*(HDRN1$Area__m2_/(a*k))^(a/(a-1)) #m3

```

## Reservoir classification by size

Classification of the reservoirs depending of the volume classes.
In lake_number.dat are not included the big reservoirs.

The classes boundaries are defined based on the storage capacities of the reservoirs. The classification present in [Mamede et al., 2018, Table 2][1] can't be represented here, as capacities of the reservoirs in HDRN1 exceeds the maximum class present in the article. So, another classification is used.

```{r class definition}
#Class boundaries definition

res_class<-c(
              102179,
              151360,
              265735,
              758010,
              875797530
            )

res_class <- c(69977.1,	124097.8,	201545.9,	403173.9,	883301)

#Classes defined based on the quantiles
#res_class<-quantile(HDRN1$capacity, probs = seq(0, 1, 0.2))
#res_class
```

## Count of the reservoirs

Count the number of reservoirs in the different volume classes

Comparing these results with the lake_number.dat file we already have it is clear that the big reservoirs aren't included in lake_number.dat
Also, the reservoirs used for this classification are the ones from the smalldams.shp, so approximately 1/10 of the reservoirs in the other shapefile.

```{r reservoir count}
#Dataframe creation: first column SubbasinID, others number of reservoirs in the classes
count_class <- subbasins %>%
                filter(!is.na(SubbasinID)) %>%
                group_by(SubbasinID) %>%
                summarize()
count_class <- data.frame(count_class$SubbasinID)
names(count_class) <- "SubbasinID"

for(i in 1:5){
  if(i != 1){
    c <- HDRN1 %>%
          filter(!is.na(SubbasinID)) %>%
          group_by(SubbasinID) %>%
      #   filter(capacity <= res_class[i+1] & capacity > res_class[i]) %>%
      #for Mamede classification
          filter(capacity <= res_class[i] & capacity > res_class[i-1]) %>%
          summarize(count=n())
  }else{
    c <- HDRN1 %>%
          filter(!is.na(SubbasinID)) %>%
          group_by(SubbasinID) %>%
          #filter(capacity <= res_class[i+1]) %>%
      #for Mamede classification
          filter(capacity <= res_class[i]) %>%
          summarize(count=n())
  }
  for(a in 1:length(c$SubbasinID)){
    for(b in 1:length(count_class$SubbasinID)){
        if(c$SubbasinID[a]==count_class$SubbasinID[b]) count_class[b,i+1]<-c$count[a]
    }
  }
}
names(count_class)<-c("SubbasinID","class1","class2","class3","class4","class5")
count_class[is.na(count_class)]<-0


115+	19	+17+	16	+3
```

## File generation

```{r lake_number.dat}
path<-"C:/Users/Utente/OneDrive - Politecnico di Milano/Backup PC/Uni/Thesis/Analysis/gen_files"

my.write(count_class,file=paste0(path,"/lake_number.dat"),
         header = "Specification of total number of reservoirs in the size classes\nSub-basin-ID, acud[-] (five reservoir size classes)",f = write.table)
```

# lake.dat

* *Reservoir_class-ID* : ID of reservoir size class
* *maxlake0*: Upper limit of reservoir size class in terms of volume [m³]
* *lake_vol0_factor*: Fraction of storage capacity that indicates the initial water volume in the reservoir size classes [-]
* *lake_change*: Factor that indicates yearly variation in the number of reservoirs of the size classes [-]
* *alpha_Molle*, *damk_Molle*: Parameters of the area-volume relationship in the reservoir size classes (Area=alpha.k.(Vol/k)alpha/(alpha-1)) [-]. Values of reservoir area and volume are expressed in m² and m³, respectively
* *damc_hrr*, *damd_hrr*: Parameters of the spillway rating curve in the reservoir size classes (Qout=damc_hrr.Hvdamd_hrr) [-]. Values of water height over the spillway and overflow discharges are expressed in m and m³/s, respectively

```{r par_class creation}

par_class<-data.frame(seq(1,5,1),     #Reservoir_class-ID
                      res_class,      #maxlake0
                      rep(1,5),       #lake_vol0_factor
                      rep(0,5),       #lake_change
                      rep(alpha_Molle,5),   
                      rep(damk_Molle,5),
                      c(12.5,18.75,25,37.5,50),       #damc_hrr
                      rep(1.5,5)      #damd_hrr
                      )
names(par_class)<-c("Reservoir_class-ID", "maxlake0_m3", "lake_vol0_factor", "lake_change", "alpha_Molle", "damk_Molle", "damc_hrr", "damd_hrr")

View(par_class)
```

## File generation

```{r lake.dat}
path<-"C:/Users/Utente/OneDrive - Politecnico di Milano/Backup PC/Uni/Thesis/Analysis/gen_files"

my.write(par_class,file=paste0(path,"/lake.dat"),
         header = "Specification of parameters for the reservoir size classes\nReservoir_class-ID, maxlake0[m**3], lake_vol0_factor[-], lake_change[-], alpha_Molle[-], damk_Molle[-], damc_hrr[-], damd_hrr[-]",f = write.table)
```

# lake_maxvol.dat

This method could be used also for the Hillslope module in case we don't understand the lumpR package/the data needed is difficult to find.

```{r lake_maxvol.dat}
#Upload of the complete file from the input files provided by Mamede

path<-"C:/Thesis_fortran/WASA/Input/Reservoir"
lake_maxvol<-read.table(paste0(path,"/lake_maxvol.dat"),skip=2,sep="\t")
names(lake_maxvol)<-c(unlist(strsplit(readLines(paste0(path,"/lake_maxvol.dat"),n=5)[2], "[,]")),"class2","class3","class4","class5")

#Select only the Banabuiu subbasins
lake_maxvol<-lake_maxvol[lake_maxvol[,1] %in% subbasins$SubbasinID,]

path<-"C:/Users/Utente/OneDrive - Politecnico di Milano/Backup PC/Uni/Thesis/Analysis/gen_files"
my.write(lake_maxvol,file=paste0(path,"/lake_maxvol.dat"),
         header = "Specification of water storage capacity for the reservoir size classes\nSub-basin-ID, maxlake[m**3] (five reservoir size classes)",f = write.table)
```

# routing.dat

```{r routing.dat}
path<-"C:/Thesis_fortran/WASA/Input/River"

#Load
routing<-read.table(paste0(path,"/routing.dat"),skip=2,sep="\t")
names(routing)<-c(unlist(strsplit(readLines(paste0(path,"/routing.dat"),n=5)[2], "[,]")))

#Cut + Order update
routing<-routing[routing$` Subasin-ID(upstream)` %in% subbasins$SubbasinID,]
routing$No.<-seq(1,length(routing$No.),1)

#Subbasin 134 ends up in Subbasin 121 which is not defined!
#How to solve this?

#File generation
path<-"C:/Users/Utente/OneDrive - Politecnico di Milano/Backup PC/Uni/Thesis/Analysis/gen_files"
my.write(routing,file=paste0(path,"/routing.dat"),
         header = "Specification of routing order (flow directions)\nNo., Subasin-ID(upstream), Subasin-ID(downstream)", f = write.table)

```

# File gereration by cutting the original files for the whole Cearà state

All the files below will be obtained starting from the files provided by Mamede, by selecting the subbasins included in the Banabuiu river basin.

* Hillslope/hymo.dat
* Hillslope/rainy_season.dat
* Hillslope/soil_vegetation.dat
* River/routing.dat   _possible problem: subbasin 121 is not defined_
* River/response.dat
* Reservoir/reservoir.dat
* Reservoir/cav.dat

```{r file cutting}
path<-"C:/Thesis_fortran/WASA/Input/Hillslope"
#hymo.dat
hymo<-read.table(paste0(path,"/hymo.dat"),skip=2,sep="\t")
names(hymo)<-c(unlist(strsplit(readLines(paste0(path,"/hymo.dat"),n=5)[2], "[,]")))
hymo<-hymo[hymo[,1] %in% subbasins$SubbasinID,]

#rainy_season.dat
rainy_season<-read.table(paste0(path,"/rainy_season.dat"),skip=3,sep="\t")
names(rainy_season)<-c(unlist(strsplit(readLines(paste0(path,"/rainy_season.dat"),n=5)[3], " ")))
rainy_season<-rainy_season[rainy_season$Subasin %in% subbasins$SubbasinID,]

#soil_vegetation.dat
soil_vegetation<-read.table(paste0(path,"/soil_vegetation.dat"),skip=3,sep="\t")
names(soil_vegetation)<-c(unlist(strsplit(readLines(paste0(path,"/soil_vegetation.dat"),n=5)[3], "[,]")))
soil_vegetation<-soil_vegetation[soil_vegetation[,1] %in% subbasins$SubbasinID,]

path<-"C:/Thesis_fortran/WASA/Input/River"
#response.dat
response<-read.table(paste0(path,"/response.dat"),skip=2,sep="\t")
names(response)<-c(unlist(strsplit(readLines(paste0(path,"/response.dat"),n=5)[2], "[,]")))
response<-response[response$`Subasin-ID` %in% subbasins$SubbasinID,]

path<-"C:/Thesis_fortran/WASA/Input/Reservoir"
#reservoir.dat
reservoir<-read.table(paste0(path,"/reservoir.dat"),skip=2,sep="\t")
names(reservoir)<-c(unlist(strsplit(readLines(paste0(path,"/reservoir.dat"),n=5)[2], "[,]")))
reservoir<-reservoir[reservoir$`Subasin-ID` %in% subbasins$SubbasinID,]

#cav.dat
cav<-read.table(paste0(path,"/cav.dat"),skip=2,sep="\t",fill=TRUE)
names(cav)<-c(unlist(strsplit(readLines(paste0(path,"/cav.dat"),n=5)[2], "[,]")))
cav<-cav[cav$`Subasin-ID` %in% subbasins$SubbasinID,]

```

## File generation

```{r gen file cut}
path<-"C:/Users/Utente/OneDrive - Politecnico di Milano/Backup PC/Uni/Thesis/Analysis/gen_files"

#hymo.dat
my.write(hymo,file=paste0(path,"/hymo.dat"),
         header = "Specification of the sub-basins and their total number, type and areal fraction of SOTER units\nSubasin-ID [-], Area[km**2],  nbr[-],  LU-IDs[-], areal fraction of Soter[-]\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t",
         f = write.table, nafill=TRUE)

#rainy_season.dat
my.write(rainy_season,file=paste0(path,"/rainy_season.dat"),
         header = "Specification of the rainy season (per year)\nfor the interpolation o temporal distribution of  vegetation characteristics (Rootdepth, height, lai, albedo)\nSubasin Year (Start-30) Startday Endday (End+30)",
         f = write.table)

#soil_vegetation.dat
my.write(soil_vegetation,file=paste0(path,"/soil_vegetation.dat"),
         header = "Specification of soil-vegetation components (links soter, terrain component, soil and vegetation properties)\nFor each block: first line Soil IDs, Second line Land use, third line fraction of SVCs in each terrain component\nSubasin-ID[-],LU-ID[-],TC-ID[-],fraction_rocky[-],nbrSVC[-],Soil-ID(30 values)[-],Vegetation-ID (30 values)[-],fraction (30 values)[-]\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t",
         f = write.table, nafill=TRUE)

#response.dat
my.write(response,file=paste0(path,"/response.dat"),
         header = "Specification of routing parameter\nSubasin-ID,lag time [d],retention [d]",
         f = write.table)

#reservoir.dat
my.write(reservoir,file=paste0(path,"/reservoir.dat"),
         header = "Specification of reservoir	parameters\nSubasin-ID, minlevel[m], maxlevel[m], vol0([1000m**3]; unknown=-999), storcap[1000m**3], damflow[m**3/s], damq_frac[-], withdrawal[m**3/s], damyear[YYYY], maxdamarea[ha], damdead[1000m**3], damalert[1000m**3], dama[-], damb[-], qoutlet[m**3/s], fvol_bottom[-], fvol_over[-], damc[-], damd[-], elevbottom[m]",
         f = write.table)

#cav.dat
my.write(cav,file=paste0(path,"/cav.dat"),
         header = "Specification of stage-area and stage-volume curves of the sub-basin’s reservoir\nSubasin-ID, nbr. points, 1st row: elevation [m], 2nd row: reservoir area [1000m**2], 3rd row: reservoir volume [1000m**3]",f = write.table,
         nafill=TRUE)

```

# Time series update

```{r}

```


# Time series cut

```{r}
path<-"C:/Thesis_fortran/WASA/Input/Time_series"

rain<-read.table(paste0(path,"/rain_daily.dat"),skip=2,sep=" ")
rain<-data.frame(rain[,1],rain[,2],rain[,rain[1,] %in% subbasins$SubbasinID])

humidity<-read.table(paste0(path,"/humidity.dat"),skip=2,sep=" ")
humidity<-data.frame(humidity[,1],humidity[,2],humidity[,humidity[1,] %in% subbasins$SubbasinID])

radiation<-read.table(paste0(path,"/radiation.dat"),skip=2,sep=" ")
radiation<-data.frame(radiation[,1],radiation[,2],radiation[,radiation[1,] %in% subbasins$SubbasinID])

temperature<-read.table(paste0(path,"/temperature.dat"),skip=2,sep=" ")
temperature<-data.frame(temperature[,1],temperature[,2],temperature[,temperature[1,] %in% subbasins$SubbasinID])

path<-"C:/Users/Utente/OneDrive - Politecnico di Milano/Backup PC/Uni/Thesis/Analysis/gen_files"

my.write(rain,file=paste0(path,"/rain_daily.dat"),
         header = "Daily average precipitation [mmd] for each subasin, ordered according Map-IDs\nDate No. of days Subasin-ID",
         f = write.table, sepset = FALSE)
my.write(humidity,file=paste0(path,"/humidity.dat"),
         header = "Daily average humidity [in %] for each subasin, ordered according to Map-IDs\nDate No. of days Subasin-ID",
         f = write.table, sepset = FALSE)
my.write(radiation,file=paste0(path,"/radiation.dat"),
         header = "Daily average shortwave radiation [in Wm2] for each subasin, ordered according to MAP-IDs\nDate No. of days Subasin-ID",
         f = write.table, sepset = FALSE)
my.write(temperature,file=paste0(path,"/temperature.dat"),
         header = "Daily average temperature (in degree Celcius) for each subasin, ordered according to Map-IDs\nDate No. of days Subasin-ID",
         f = write.table, sepset = FALSE)
```


# References

[1]: https://doi.org/10.1061/(ASCE)HE.1943-5584.0001701
