prec2020$date <- create_date_vector(2020, 2020)
prec2020 <- prec2020 %>% relocate(date, .before = X1)
output_prec2020 <- create_time_series_Wmean(main_dataframe = prec2020,
positions = positions_prec2020,
layer = subbasins)
#Join them
output_prec <- rbind(output_prec2019, output_prec2020)
output_prec$date <- create_date_vector(2019, 2020)
#Save
h = "Daily average precipitation [mmd] for each subasin, ordered according Map-IDs\nDate No. of days Subasin-ID\n0 0 123 125 126 127 134 137 138 139 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160"
output_prec <- WASA_input_format(output_prec, output_prec, header = h, path = path_export, name = "prec_20192020")
save(output_rad, file = paste0(path_export, "/prec_20192020.RData"))
toc()
path = "C:/Users/Utente/OneDrive - Politecnico di Milano/Backup PC/Uni/Thesis/Data/FUNCEME_update/inmet_temperatura_do_ar_a_2m_ceara"
temp_input = create_data_list(path, c("date","value"), s = ',')
positions_temp <- create_position_vector(temp_input[[1]])
temp_input[[2]] <- add_date_column(temp_input[[2]], complete = TRUE)
View(add_date_column)
source("./Libraries/Functions_TG.R")
source("./Libraries/Functions_DP.R")
source("./Libraries/Functions_CO.R")
source("./Libraries/Functions_MC.R")
setwd("C:/Users/Utente/OneDrive - Politecnico di Milano/Backup PC/Uni/Thesis/Directory_thesis_codes")
path_export <- "./Inputs/Model_input/Model_enhancement/Time_series_update"
source("./Libraries/Libraries.R")
source("./Libraries/Functions.R")
source("./Libraries/Functions_TG.R")
source("./Libraries/Functions_DP.R")
source("./Libraries/Functions_CO.R")
source("./Libraries/Functions_MC.R")
View(create_time_series_Wmean)
View(positions_prec2019)
View(main_dataframe_rad)
View(main_dataframe_hum)
View(prec2019)
prec2020[prec2020 == -999] <- NA
prec2019[prec2019 == -999] <- NA
temp_input = create_data_list(path, c("date","value"), s = ',')
positions_temp <- create_position_vector(temp_input[[1]])
temp_input[[2]] <- add_date_column(temp_input[[2]], complete = TRUE)
date <- create_date_vector(2019, 2020)
main_dataframe_temp <- create_main_dataframe(date, temp_input[[2]], positions_temp,
timecol = 1, datacol = 2)
View(main_dataframe_temp)
is.na(main_dataframe_temp$St624)
#Model enhancement #1
#Increase the observation period, adding the observations for
# Setup -------------------------------------------------------------------
setwd("C:/Users/Utente/OneDrive - Politecnico di Milano/Backup PC/Uni/Thesis/Directory_thesis_codes")
path_export <- "./Inputs/Model_input/Model_enhancement/Time_series_update"
source("./Libraries/Libraries.R")
source("./Libraries/Functions.R")
source("./Libraries/Functions_TG.R")
source("./Libraries/Functions_DP.R")
source("./Libraries/Functions_CO.R")
source("./Libraries/Functions_MC.R")
#Load the subbasins' shapefile
path<-"C:/Users/Utente/OneDrive - Politecnico di Milano/Backup PC/Uni/Thesis/Data/shapefile/Banabuiu"
subbasins<-readOGR(paste0(path,"/subbasins_cut_geomfix.shp"))
# Temperature -------------------------------------------------------------
path = "C:/Users/Utente/OneDrive - Politecnico di Milano/Backup PC/Uni/Thesis/Data/FUNCEME_update/inmet_temperatura_do_ar_a_2m_ceara"
temp_input = create_data_list(path, c("date","value"), s = ',')
tic("Temperature - 2018-2020 - Interpolation")
positions_temp <- create_position_vector(temp_input[[1]])
temp_input[[2]] <- add_date_column(temp_input[[2]], complete = TRUE)
date <- create_date_vector(2019, 2020)
main_dataframe_temp <- create_main_dataframe(date, temp_input[[2]], positions_temp,
timecol = 1, datacol = 2)
output_temp <- create_time_series_Wmean(main_dataframe = main_dataframe_temp,
positions = positions_temp,
layer = subbasins)
h = "Daily average temperature (in degree Celcius) for each subasin, ordered according Map-IDs\nDate No. of days Subasin-ID\n0 0 123 125 126 127 134 137 138 139 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160"
output_temp <- WASA_input_format(main_dataframe_temp, output_temp, header = h, path = path_export, name = "temperature_20192020")
save(output_temp, file = paste0(path_export, "/temperature_20192020.RData"))
toc()
# Humidity ----------------------------------------------------------------
path = "C:/Users/Utente/OneDrive - Politecnico di Milano/Backup PC/Uni/Thesis/Data/FUNCEME_update/inmet_relative_humidity_ceara"
hum_input = create_data_list(path, c("date","value"), s = ',')
tic("Humidity - 2018-2020 - Interpolation")
positions_hum <- create_position_vector(hum_input[[1]])
hum_input[[2]] <- add_date_column(hum_input[[2]], complete = TRUE)
date <- create_date_vector(2019, 2020)
main_dataframe_hum <- create_main_dataframe(date, hum_input[[2]], positions_hum,
timecol = 1, datacol = 2)
#Anomalous behavior for St116
main_dataframe_hum$St116[main_dataframe_hum$date <= as.Date("2018-10-23")] <- NA
output_hum <- create_time_series_Wmean(main_dataframe = main_dataframe_hum,
positions = positions_hum,
layer = subbasins)
h = "Daily average humidity [in %] for each subasin, ordered according Map-IDs\nDate No. of days Subasin-ID\n0 0 123 125 126 127 134 137 138 139 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160"
output_hum <- WASA_input_format(main_dataframe_hum, output_hum, header = h, path = path_export, name = "humidity_20192020")
save(output_hum, file = paste0(path_export, "/humidity_20192020.RData"))
toc() #3 minutes
# Radiation ---------------------------------------------------------------
#Radiation data had missing data from June 2018, so here I will extract
#2018 as well, and then replace it in the actual file
path = "C:/Users/Utente/OneDrive - Politecnico di Milano/Backup PC/Uni/Thesis/Data/FUNCEME_update/inmet_downwelling_shortwave_radiation_ceara"
rad_input = create_data_list(path, c("date","value"), s = ',')
tic("Radiation - 2018-2020 - Interpolation")
positions_rad <- create_position_vector(rad_input[[1]])
rad_input[[2]] <- add_date_column(rad_input[[2]], complete = TRUE)
date <- create_date_vector(2018, 2020)
main_dataframe_rad <- create_main_dataframe(date, rad_input[[2]], positions_rad,
timecol = 1, datacol = 2)
output_rad <- create_time_series_Wmean(main_dataframe = main_dataframe_rad,
positions = positions_rad,
layer = subbasins)
h = "Daily average shortwave radiation [in Wm2] for each subasin, ordered according Map-IDs\nDate No. of days Subasin-ID\n0 0 123 125 126 127 134 137 138 139 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160"
output_rad <- WASA_input_format(main_dataframe_rad, output_rad, header = h, path = path_export, name = "radiation_20182020")
save(output_rad, file = paste0(path_export, "/radiation_20182020.RData"))
toc() #3 minutes
# Precipitation ------------------------------------------------------------
tic('Precipitation')
#Load the data
path = "C:/Users/Utente/OneDrive - Politecnico di Milano/Backup PC/Uni/Thesis/Data/FUNCEME_update"
prec2019 <- read.table(paste0(path, "/pr_daily_funceme_20190101_20191231.asc"))
prec2020 <- read.table(paste0(path, "/pr_daily_funceme_20200101_20201231.asc"))
prec2019 <- data.frame(t(prec2019))
prec2020 <- data.frame(t(prec2020))
#2019
positions_prec2019 <- data.frame(ID = names(prec2019), name = '-', long = 0, lat = 0)
positions_prec2019$long <- t(prec2019[2, ])
positions_prec2019$lat <- t(prec2019[3, ])
prec2019 <- prec2019[-c(1, 2, 3), ]
prec2019[prec2019 == -999] <- NA
prec2019$date <- create_date_vector(2019, 2019)
prec2019 <- prec2019 %>% relocate(date, .before = X1)
output_prec2019 <- create_time_series_Wmean(main_dataframe = prec2019,
positions = positions_prec2019,
layer = subbasins)
#2020
positions_prec2020 <- data.frame(ID = names(prec2020), name = '-', long = 0, lat = 0)
positions_prec2020$long <- t(prec2020[2, ])
positions_prec2020$lat <- t(prec2020[3, ])
prec2020 <- prec2020[-c(1, 2, 3), ]
prec2020[prec2020 == -999] <- NA
prec2020$date <- create_date_vector(2020, 2020)
prec2020 <- prec2020 %>% relocate(date, .before = X1)
output_prec2020 <- create_time_series_Wmean(main_dataframe = prec2020,
positions = positions_prec2020,
layer = subbasins)
#Join them
output_prec <- rbind(output_prec2019, output_prec2020)
output_prec$date <- create_date_vector(2019, 2020)
#Save
h = "Daily average precipitation [mmd] for each subasin, ordered according Map-IDs\nDate No. of days Subasin-ID\n0 0 123 125 126 127 134 137 138 139 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160"
output_prec <- WASA_input_format(output_prec, output_prec, header = h, path = path_export, name = "prec_20192020")
save(output_rad, file = paste0(path_export, "/prec_20192020.RData"))
toc()
prec <- read.table("./Inputs/Model_input/Base/Time_series/rain_daily.dat", skip = 3)
temp <- read.table("./Inputs/Model_input/Base/Time_series/temperature.dat", skip = 3)
hum <- read.table("./Inputs/Model_input/Base/Time_series/humidity.dat", skip = 3)
rad <- read.table("./Inputs/Model_input/Base/Time_series/radiation.dat", skip = 3)
columns <- names(output_prec)
names(prec) <- columns
names(temp) <- columns
names(hum) <- columns
names(rad) <- columns
prec_f <- rbind(prec, output_prec)
temp_f <- rbind(temp, output_temp)
hum_f <- rbind(hum, output_hum)
replace_d <- create_date_vector(2018, 2018)
rad$date <- change_date_WASA_input(rad$date)
output_rad$date <- change_date_WASA_input(output_rad$date)
rad[rad$date %in% replace_d, ] <- output_rad[output_rad$date %in% replace_d, ]
output_rad <- output_rad[-which(output_rad$date %in% replace_d), ]
rad_f <- rbind(rad, output_rad)
View(rad)
View(prec_f)
#Save the datasets
date_df <- data.frame(date = create_date_vector(1980, 2020))
h = "Daily average precipitation [mmd] for each subasin, ordered according Map-IDs\nDate No. of days Subasin-ID\n0 0 123 125 126 127 134 137 138 139 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160"
prec_f <- WASA_input_format(date_df, prec_f, header = h, path = path_export, name = "rain_daily")
View(prec_f)
#intake.dat generation
# Setup -------------------------------------------------------------------
setwd("C:/Users/Utente/OneDrive - Politecnico di Milano/Backup PC/Uni/Thesis/Directory_thesis_codes")
source("./Libraries/Libraries.R")
source("./Libraries/Functions.R")
path_export <- "./Inputs/Model_input/Model_enhancement/Time_series_update"
# Load files --------------------------------------------------------------
path<-"C:/Users/Utente/OneDrive - Politecnico di Milano/Backup PC/Uni/Thesis/Data/waterdrawal_banabuiu_basin/renamed"
index_files <- data.frame(list.files(path = path, full.names = T, recursive = TRUE))
names(index_files) <- "path"
index_files$SubbasinID <- gsub("\\..*","",basename(index_files$path))
withdrawal_list<-list()
for(i in 1:nrow(index_files)){
name<-paste0("res_",index_files$SubbasinID[i])
withdrawal_list[[name]]<-read.csv(index_files$path[i], header = TRUE, sep = ",")
}
#Change the format of the date column to date
for(i in 1:length(withdrawal_list[])){
withdrawal_list[[i]][["date"]] <- as.Date(withdrawal_list[[i]][["date"]])
}
#Check the percentage of NAs in the observations
for(i in 1:length(withdrawal_list[])){
print(sum(is.na(withdrawal_list[[i]]$flow))/length(withdrawal_list[[i]]$flow))
}
# Create the dataframe ----------------------------------------------------
#Specify the date range
#Create the date vector
start_y <- 1980
end_y <- 2020 #2018
start_m <- 01
end_m <- 12
start<-paste0("01/0",start_m,"/",start_y)
end<-paste0("31/",end_m,"/",end_y)
date<-seq(as.Date(start,"%d/%m/%Y"), as.Date(end,"%d/%m/%Y"), by="days")
#Create the dataframe
withdrawal_df<-data.frame(date)
withdrawal_df$doy<-NA
for(i in 1:length(withdrawal_list[])){
new_v<-sistemadati_DCA(vettore = withdrawal_list[[i]], lung = nrow(withdrawal_df), g = date,
coltime = 1, coldata = 2)
withdrawal_df$new<-new_v[,2]
names(withdrawal_df)[names(withdrawal_df) == "new"]<-index_files$SubbasinID[i]
}
#Plot to check anomalies
# source("Functions_CO.R")
# path_plot <- "C:/Users/Utente/OneDrive - Politecnico di Milano/Backup PC/Uni/Thesis/Analysis/Model_calibration"
# plot_subbasins_df(withdrawal_df, y = "m3/s", label = "Withdrawal",
#                   interactive = TRUE, file = "withdrawal_line", path = path_plot, line = TRUE)
#Change the NA values to -999
withdrawal_df[,3:ncol(withdrawal_df)][is.na(withdrawal_df[,3:ncol(withdrawal_df)])] <- -999
#Put the dataframe in the WASA format and save it
WASA_input_format_intake = function(df, header, path, name){
year<-lubridate::year(df$date)
month<-lubridate::month(df$date)
month[which(month < 10)]<-paste0("0",month[which(month < 10)])
day<-lubridate::day(df$date)
#day[which(day < 10)]<-paste0("0",day[which(day < 10)])
#Insert the number of days
df$doy<-lubridate::yday(df$date)
#Insert the date in the WASA format
df$date<-paste0(day,month,year)
my.write(df, file = paste0(path,"/", name,".dat"),
header = header, f = write.table, sepset = TRUE)
return(df)
}
#path_export <- "C:/Users/Utente/OneDrive - Politecnico di Milano/Backup PC/Uni/Thesis/Analysis/time_series_generation/input_WASA_gen"
h <- "# Specification of controlled release through reservoir's intake devices in [m3/s]\nDate,\tDoy,\t123,\t125,\t126,\t127,\t138,\t142,\t143,\t145,\t146,\t147,\t148,\t149,\t150,\t151,\t152,\t153,\t154,\t156,\t160"
withdrawal_df_WASA <- WASA_input_format_intake(withdrawal_df, h, path_export, "intake")
load(paste0(path_export, "/radiation_20182020.RData"))
View(output_rad)
replace_d <- create_date_vector(2018, 2018)
rad$date <- change_date_WASA_input(rad$date)
View(rad)
output_rad$date <- change_date_WASA_input(output_rad$date)
change_date_WASA_input(output_rad$date)
output_rad$date
rad <- read.table("./Inputs/Model_input/Base/Time_series/radiation.dat", skip = 3)
columns <- names(output_prec)
#c("date", "doy", "ID123", "ID125", "ID126", "ID127", "ID134", "ID137", "ID138", "ID139", "ID142", "ID143", "ID144", "ID145", "ID146", "ID147", "ID148", "ID149", "ID150", "ID151", "ID152", "ID153", "ID154", "ID155", "ID156", "ID157", "ID158", "ID159", "ID160")
names(prec) <- columns
names(temp) <- columns
names(hum) <- columns
names(rad) <- columns
rad$date <- change_date_WASA_input(rad$date)
output_rad$date <- change_date_WASA_input(output_rad$date)
View(change_date_WASA_input)
as.numeric(output_rad$date)
output_rad$date <- change_date_WASA_input(as.numeric(output_rad$date))
rad[rad$date %in% replace_d, ] <- output_rad[output_rad$date %in% replace_d, ]
output_rad <- output_rad[-which(output_rad$date %in% replace_d), ]
rad_f <- rbind(rad, output_rad)
View(rad_f)
load(paste0(path_export, "/temperature_20192020.RData"))
load(paste0(path_export, "/humidity_20192020.RData"))
load(paste0(path_export, "/radiation_20182020.RData"))
load(paste0(path_export, "/prec_20192020.RData"))
#Actual dataset
prec <- read.table("./Inputs/Model_input/Base/Time_series/rain_daily.dat", skip = 3)
temp <- read.table("./Inputs/Model_input/Base/Time_series/temperature.dat", skip = 3)
hum <- read.table("./Inputs/Model_input/Base/Time_series/humidity.dat", skip = 3)
rad <- read.table("./Inputs/Model_input/Base/Time_series/radiation.dat", skip = 3)
columns <- names(output_prec)
#c("date", "doy", "ID123", "ID125", "ID126", "ID127", "ID134", "ID137", "ID138", "ID139", "ID142", "ID143", "ID144", "ID145", "ID146", "ID147", "ID148", "ID149", "ID150", "ID151", "ID152", "ID153", "ID154", "ID155", "ID156", "ID157", "ID158", "ID159", "ID160")
names(prec) <- columns
names(temp) <- columns
names(hum) <- columns
names(rad) <- columns
prec_f <- rbind(prec, output_prec)
temp_f <- rbind(temp, output_temp)
hum_f <- rbind(hum, output_hum)
replace_d <- create_date_vector(2018, 2018)
rad$date <- change_date_WASA_input(rad$date)
output_rad$date <- change_date_WASA_input(as.numeric(output_rad$date))
rad[rad$date %in% replace_d, ] <- output_rad[output_rad$date %in% replace_d, ]
output_rad <- output_rad[-which(output_rad$date %in% replace_d), ]
rad_f <- rbind(rad, output_rad)
#Save the datasets
date_df <- data.frame(date = create_date_vector(1980, 2020))
h = "Daily average precipitation [mmd] for each subasin, ordered according Map-IDs\nDate No. of days Subasin-ID\n0 0 123 125 126 127 134 137 138 139 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160"
prec_f <- WASA_input_format(date_df, prec_f, header = h, path = path_export, name = "rain_daily")
h = "Daily average temperature (in degree Celcius) for each subasin, ordered according Map-IDs\nDate No. of days Subasin-ID\n0 0 123 125 126 127 134 137 138 139 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160"
temp_f <- WASA_input_format(date_df, temp_f, header = h, path = path_export, name = "temperature")
h = "Daily average humidity [in %] for each subasin, ordered according Map-IDs\nDate No. of days Subasin-ID\n0 0 123 125 126 127 134 137 138 139 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160"
hum_f <- WASA_input_format(date_df, hum_f, header = h, path = path_export, name = "humidity")
h = "Daily average shortwave radiation [in Wm2] for each subasin, ordered according Map-IDs\nDate No. of days Subasin-ID\n0 0 123 125 126 127 134 137 138 139 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160"
rad_f <- WASA_input_format(date_df, rad_f, header = h, path = path_export, name = "radiation")
path <- "./Inputs/Model_input/Model_enhancement/Time_series_update"
prec <- read.table(paste0(path, "/rain_daily.dat"), skip = 3)
columns <- c("date", "n_days", "ID123", "ID125", "ID126", "ID127", "ID134", "ID137", "ID138", "ID139", "ID142", "ID143", "ID144", "ID145", "ID146", "ID147", "ID148", "ID149", "ID150", "ID151", "ID152", "ID153", "ID154", "ID155", "ID156", "ID157", "ID158", "ID159", "ID160")
names(prec) <- columns
prec$date <- change_date_WASA_input(prec$date)
get_rainy_season = function(df, years, date_col = 1, skip = 2){
#The rainy season in North-East Brazil goes from January to June.
#This function will extract the first occurrence of rain in January and the last
#occurrence of rain in June for the precipitation data in input (df).
#If no rain is found in January, the first day is searched in the following
#months. If no rain is found in June, the last day is searched in the previous
#months.
start_m <- 1 #January
end_m <- 6 #June
skip <- skip + 1
rainy_season <- data.frame(rep(colnames(df)[skip:ncol(df)], length(years)),
year = 0, start_30 = 0, start = 0, end = 0, end_30 = 0)
names(rainy_season) <- c('ID', 'year', 'start_30', 'start', 'end', 'end_30')
k <- 1
for(j in 1:length(years)){
for(i in skip:ncol(df)){
v <- df[which(lubridate::year(df[,date_col]) == years[j] &
lubridate::month(df[, date_col]) == start_m), c(1,i)]
while(is_empty(which(v[,2] > 0)) & start_m <= 12){
start_m <- start_m + 1
v <- df[which(lubridate::year(df[,date_col]) == years[j] &
lubridate::month(df[, date_col]) == start_m), c(1,i)]
}
rainy_season$year[k] <- years[j]
rainy_season$start[k] <- lubridate::yday(v[which(v[,2] > 0)[1], 1])
v <- df[which(lubridate::year(df[,date_col]) == years[j] &
lubridate::month(df[, date_col]) == end_m), c(1,i)]
while(is_empty(which(v[,2] > 0)) & end_m >= 1){
end_m <- end_m - 1
v <- df[which(lubridate::year(df[,date_col]) == years[j] &
lubridate::month(df[, date_col]) == end_m), c(1,i)]
}
rainy_season$end[k] <- lubridate::yday(v[which(v[,2] > 0)[length(which(v[,2] > 0))], 1])
k <- k + 1
start_m <- 1
end_m <- 6
}
}
rainy_season$start_30 <- rainy_season$start - 30
rainy_season$end_30 <- rainy_season$end + 30
return(rainy_season)
}
years <- seq(1980, 2018, 1)
rainy_season <- get_rainy_season(prec, years)
View(rainy_season)
years <- seq(1980, 2020, 1)
rainy_season <- get_rainy_season(prec, years)
substrRight <- function(x, n){
substr(x, nchar(x)-n+1, nchar(x))
}
rainy_season$ID <- substrRight(rainy_season$ID,3)
#path_export <- path
h <- "Specification of the rainy season (per year)\nfor the interpolation o temporal distribution of  vegetation characteristics (Rootdepth, height, lai, albedo)\nSubasin Year (Start-30) Startday Endday (End+30)"
rseason_out <- my.write(rainy_season, paste0(path_export, "/rainy_season.dat"), header = h, f = write.table)
# path_export <- "./Inputs/Model_input/Model_enhancement/Time_series_update"
path_export <- "./Inputs/Model_input/Model_enhancement/Time_series_reanalysis"
#intake.dat generation
# Setup -------------------------------------------------------------------
setwd("C:/Users/Utente/OneDrive - Politecnico di Milano/Backup PC/Uni/Thesis/Directory_thesis_codes")
source("./Libraries/Libraries.R")
source("./Libraries/Functions.R")
# path_export <- "./Inputs/Model_input/Model_enhancement/Time_series_update"
path_export <- "./Inputs/Model_input/Model_enhancement/Time_series_reanalysis"
# Load files --------------------------------------------------------------
path<-"C:/Users/Utente/OneDrive - Politecnico di Milano/Backup PC/Uni/Thesis/Data/waterdrawal_banabuiu_basin/renamed"
index_files <- data.frame(list.files(path = path, full.names = T, recursive = TRUE))
names(index_files) <- "path"
index_files$SubbasinID <- gsub("\\..*","",basename(index_files$path))
withdrawal_list<-list()
for(i in 1:nrow(index_files)){
name<-paste0("res_",index_files$SubbasinID[i])
withdrawal_list[[name]]<-read.csv(index_files$path[i], header = TRUE, sep = ",")
}
#Change the format of the date column to date
for(i in 1:length(withdrawal_list[])){
withdrawal_list[[i]][["date"]] <- as.Date(withdrawal_list[[i]][["date"]])
}
#Check the percentage of NAs in the observations
for(i in 1:length(withdrawal_list[])){
print(sum(is.na(withdrawal_list[[i]]$flow))/length(withdrawal_list[[i]]$flow))
}
# Create the dataframe ----------------------------------------------------
#Specify the date range
#Create the date vector
start_y <- 1981
end_y <- 2020 #2018
start_m <- 01
end_m <- 12
start<-paste0("01/0",start_m,"/",start_y)
end<-paste0("31/",end_m,"/",end_y)
date<-seq(as.Date(start,"%d/%m/%Y"), as.Date(end,"%d/%m/%Y"), by="days")
#Create the dataframe
withdrawal_df<-data.frame(date)
withdrawal_df$doy<-NA
for(i in 1:length(withdrawal_list[])){
new_v<-sistemadati_DCA(vettore = withdrawal_list[[i]], lung = nrow(withdrawal_df), g = date,
coltime = 1, coldata = 2)
withdrawal_df$new<-new_v[,2]
names(withdrawal_df)[names(withdrawal_df) == "new"]<-index_files$SubbasinID[i]
}
#Plot to check anomalies
# source("Functions_CO.R")
# path_plot <- "C:/Users/Utente/OneDrive - Politecnico di Milano/Backup PC/Uni/Thesis/Analysis/Model_calibration"
# plot_subbasins_df(withdrawal_df, y = "m3/s", label = "Withdrawal",
#                   interactive = TRUE, file = "withdrawal_line", path = path_plot, line = TRUE)
#Change the NA values to -999
withdrawal_df[,3:ncol(withdrawal_df)][is.na(withdrawal_df[,3:ncol(withdrawal_df)])] <- -999
#Put the dataframe in the WASA format and save it
WASA_input_format_intake = function(df, header, path, name){
year<-lubridate::year(df$date)
month<-lubridate::month(df$date)
month[which(month < 10)]<-paste0("0",month[which(month < 10)])
day<-lubridate::day(df$date)
#day[which(day < 10)]<-paste0("0",day[which(day < 10)])
#Insert the number of days
df$doy<-lubridate::yday(df$date)
#Insert the date in the WASA format
df$date<-paste0(day,month,year)
my.write(df, file = paste0(path,"/", name,".dat"),
header = header, f = write.table, sepset = TRUE)
return(df)
}
#path_export <- "C:/Users/Utente/OneDrive - Politecnico di Milano/Backup PC/Uni/Thesis/Analysis/time_series_generation/input_WASA_gen"
h <- "# Specification of controlled release through reservoir's intake devices in [m3/s]\nDate,\tDoy,\t123,\t125,\t126,\t127,\t138,\t142,\t143,\t145,\t146,\t147,\t148,\t149,\t150,\t151,\t152,\t153,\t154,\t156,\t160"
withdrawal_df_WASA <- WASA_input_format_intake(withdrawal_df, h, path_export, "intake")
#rainy_season.dat update
# Setup -------------------------------------------------------------------
setwd("C:/Users/Utente/OneDrive - Politecnico di Milano/Backup PC/Uni/Thesis/Directory_thesis_codes")
# path_export <- "./Inputs/Model_input/Model_enhancement/Time_series_update"
path_export <- "./Inputs/Model_input/Model_enhancement/Time_series_reanalysis"
source("./Libraries/Libraries.R")
source("./Libraries/Functions.R")
source("./Libraries/Functions_CO.R")
# Load the precipitation time series --------------------------------------
# path <- "./Inputs/Model_input/Model_enhancement/Time_series_update"
path <- "./Inputs/Model_input/Model_enhancement/Time_series_reanalysis"
prec <- read.table(paste0(path, "/rain_daily.dat"), skip = 3)
columns <- c("date", "n_days", "ID123", "ID125", "ID126", "ID127", "ID134", "ID137", "ID138", "ID139", "ID142", "ID143", "ID144", "ID145", "ID146", "ID147", "ID148", "ID149", "ID150", "ID151", "ID152", "ID153", "ID154", "ID155", "ID156", "ID157", "ID158", "ID159", "ID160")
names(prec) <- columns
prec$date <- change_date_WASA_input(prec$date)
# Compute the rainy season file -------------------------------------------
#For each subbasin, extract the first day of the year with precipitation > 0
#and the last day of the year with precipitation > 0, for each year
get_rainy_season = function(df, years, date_col = 1, skip = 2){
#The rainy season in North-East Brazil goes from January to June.
#This function will extract the first occurrence of rain in January and the last
#occurrence of rain in June for the precipitation data in input (df).
#If no rain is found in January, the first day is searched in the following
#months. If no rain is found in June, the last day is searched in the previous
#months.
start_m <- 1 #January
end_m <- 6 #June
skip <- skip + 1
rainy_season <- data.frame(rep(colnames(df)[skip:ncol(df)], length(years)),
year = 0, start_30 = 0, start = 0, end = 0, end_30 = 0)
names(rainy_season) <- c('ID', 'year', 'start_30', 'start', 'end', 'end_30')
k <- 1
for(j in 1:length(years)){
for(i in skip:ncol(df)){
v <- df[which(lubridate::year(df[,date_col]) == years[j] &
lubridate::month(df[, date_col]) == start_m), c(1,i)]
while(is_empty(which(v[,2] > 0)) & start_m <= 12){
start_m <- start_m + 1
v <- df[which(lubridate::year(df[,date_col]) == years[j] &
lubridate::month(df[, date_col]) == start_m), c(1,i)]
}
rainy_season$year[k] <- years[j]
rainy_season$start[k] <- lubridate::yday(v[which(v[,2] > 0)[1], 1])
v <- df[which(lubridate::year(df[,date_col]) == years[j] &
lubridate::month(df[, date_col]) == end_m), c(1,i)]
while(is_empty(which(v[,2] > 0)) & end_m >= 1){
end_m <- end_m - 1
v <- df[which(lubridate::year(df[,date_col]) == years[j] &
lubridate::month(df[, date_col]) == end_m), c(1,i)]
}
rainy_season$end[k] <- lubridate::yday(v[which(v[,2] > 0)[length(which(v[,2] > 0))], 1])
k <- k + 1
start_m <- 1
end_m <- 6
}
}
rainy_season$start_30 <- rainy_season$start - 30
rainy_season$end_30 <- rainy_season$end + 30
return(rainy_season)
}
years <- seq(1981, 2020, 1)
rainy_season <- get_rainy_season(prec, years)
# Export in the WASA input format -----------------------------------------
substrRight <- function(x, n){
substr(x, nchar(x)-n+1, nchar(x))
}
rainy_season$ID <- substrRight(rainy_season$ID,3)
#path_export <- path
h <- "Specification of the rainy season (per year)\nfor the interpolation o temporal distribution of  vegetation characteristics (Rootdepth, height, lai, albedo)\nSubasin Year (Start-30) Startday Endday (End+30)"
rseason_out <- my.write(rainy_season, paste0(path_export, "/rainy_season.dat"), header = h, f = write.table)
hum <- read.table("./Inputs/Model_input/Model_enhancement/Time_series_update/humidity.dat", skip = 3)
columns <- c("date", "doy", "ID123", "ID125", "ID126", "ID127", "ID134", "ID137", "ID138", "ID139", "ID142", "ID143", "ID144", "ID145", "ID146", "ID147", "ID148", "ID149", "ID150", "ID151", "ID152", "ID153", "ID154", "ID155", "ID156", "ID157", "ID158", "ID159", "ID160")
names(hum) <- columns
hum$date <- change_date_WASA_input(hum$date)
hum<- hum[hum$date >= as.Date("1981-01-01")]
View(hum)
hum<- hum[hum$date >= as.Date("1981-01-01"), ]
View(hum)
path_export <- "./Inputs/Model_input/Model_enhancement/Time_series_reanalysis"
h = "Daily average humidity [in %] for each subasin, ordered according Map-IDs\nDate No. of days Subasin-ID\n0 0 123 125 126 127 134 137 138 139 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160"
output_hum <- WASA_input_format(hum, hum, header = h, path = path_export, name = "humidity")
View(output_hum)
