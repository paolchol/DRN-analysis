---
title: "Drought Cycle Analysis"
author: "Paolo Colombo"
date: "17/5/2021"
output: html_document
---

# Why the Drought Cycle Analysis

By looking at the precipitation index and at the volume of the monitored reservoirs, we can determine if the area we are considering is in a drought condition, and in which phase it is in. By considering two different scenarios (one including the HDRN and one excluding it), we can evaluate the differences in the drought cycles generated by the presence of the HDRN.

Drought Cycle Analysis can then express the impacts of the HDRN on the centralized reservoirs system, by checking how the volume deficit of the monitored reservoirs changes during time.

# Steps for the Drought Cycle Analysis

The Drought Cycle Analysis is carried forward through the classification of drought events into four possible stages regarding the simultaneous occurrence of precipitation deficit and water storage deficit. It uses the Precipitation Index (PI) and the Water Storage Index (WSI).
-	Wet quadrant (non-occurrence of drought):   PI > 0		WSI > 0
-	Meteorological drought:                     PI < 0		WSI > 0
-	Hydro-meteorological drought:               PI < 0		WSI < 0
-	Hydrological drought:                       PI > 0		WSI < 0

* **PI**: SPI12 within CHIRPS data
* **WSI**: obtained by considering the variation of the largest and most important reservoir in the area as a proxy. The variation (called Volume Deficit, VD) was standardized considering a deviation from halved maximum capacity. It thus varies from -1 to 1.

## Libraries and functions

```{r libraries and functions}
setwd("C:/Users/Utente/OneDrive - Politecnico di Milano/Backup PC/Uni/Thesis/Analysis")

source("Libraries.R")
source("Functions.R")
```

## Pre-steps

```{r}
#Load the IDs of subbasins in the Banabuiu region 
path<-"C:/Users/Utente/OneDrive - Politecnico di Milano/Backup PC/Uni/Thesis/Analysis"
reservoirs<-read.table(paste0(path,"/reservoir_name_ID.txt"), header = TRUE, sep = "\t")

#Create the date vector
start_y <- 1980
end_y <- 2020   #change to 2020 when actually using the updated time series
start_m <- 01
end_m <- 12

start<-paste0("01/0",start_m,"/",start_y)
end<-paste0("31/",end_m,"/",end_y)
date<-seq(as.Date(start,"%d/%m/%Y"), as.Date(end,"%d/%m/%Y"), by="days")
```

## SPI12

Monthly sum of the precipitation for each subbasins and for the whole basin, considering a one year window.

Do this for each subbasin and for the whole Banabuiu (by summing the precipitation in each subbasin)

```{r precipitation dataframe}
#Create the dataset
#Three columns: Year, Month, Precipitation

#Upload the precipitation dataframe generated by Thiessen polygons
path<-"C:/Users/Utente/OneDrive - Politecnico di Milano/Backup PC/Uni/Thesis/Analysis/time_series_generation/output_time_series_gen"
prec_Banabuiu<-read.table(paste0(path,"/output_prec_save_v2.txt"), header = TRUE, sep = "\t")

#Change the date format of the precipitation dataframe
prec_Banabuiu$date<-date

#Separate months and years in the precipitation dataframe
prec_Banabuiu$year<-lubridate::year(prec_Banabuiu$date)
prec_Banabuiu$month<-lubridate::month(prec_Banabuiu$date)

#Create a new dataframe with monthly sums of daily precipitation
for(i in 0:(end_y-start_y)){
  year<-rep(start_y+i,12)
  month<-seq(1,12,1)
  if(i != 0){
    month_prec_Banabuiu<-rbind(month_prec_Banabuiu,data.frame(year,month))
  }else  month_prec_Banabuiu<-data.frame(year, month)
}

#Add the monthly sums for each reservoir
for(i in 1:nrow(reservoirs)){
  n<-as.numeric(reservoirs$SubbasinID[i])+2
  month_prec_Banabuiu$new<-rep(0,nrow(month_prec_Banabuiu))
  for(j in 1:nrow(month_prec_Banabuiu)){
  month_prec_Banabuiu$new[j]<-
    sum(prec_Banabuiu[,n][which(prec_Banabuiu$year == month_prec_Banabuiu$year[j] &
                          prec_Banabuiu$month == month_prec_Banabuiu$month[j])],
        na.rm = TRUE)
  }
  names(month_prec_Banabuiu)[names(month_prec_Banabuiu) == "new"]<-
    paste0("SubID_",as.numeric(reservoirs$SubbasinID[i]))
}
month_prec_Banabuiu$Banabuiu<-0
for(i in 1:nrow(month_prec_Banabuiu)){
  month_prec_Banabuiu$Banabuiu[i]<-sum(month_prec_Banabuiu[i,3:ncol(month_prec_Banabuiu)]) 
}

month_prec_Banabuiu[,3:ncol(month_prec_Banabuiu)]<-
  round(month_prec_Banabuiu[,3:ncol(month_prec_Banabuiu)],3)
```

```{r SPI computation}
library(SPEI)

list_spi<-list()
j<-1
for(i in 3:ncol(month_prec_Banabuiu)){
  list_spi[[j]]<-spi(month_prec_Banabuiu[,i], 12)
  j<-j+1
}
names(list_spi)<-paste0("SPI12_",names(month_prec_Banabuiu)[3:ncol(month_prec_Banabuiu)])

for(i in 1:length(list_spi)){
  plot.spei(list_spi[[i]], main = paste0("SPI12 of ",names(month_prec_Banabuiu)[i+2]))
}
#plot(list_spi$SPI12_SubID_123$fitted)
#plot.spei(list_spi$SPI12_SubID_123)

#Find a better way to visualize it, for now this is enough
#The SPI result is stored in $fitted
```

## Volume deficit

Consider the median of the time series of reservoirs' volumes
Then, calculate VD as the difference between the median and the volume at each time, and standardize it

Germano in his study used only the variation of the biggest monitored reservoir as an index, so:

* Implement the VD by considering only the biggest reservoir in the Banabuiu region
* Implement the VD by considering the variation of each monitored reservoirs from its own median. Standardize each VD, then take the mean of all of them

### Data input

```{r reservoirs model dataframe}
#Create a column containing the WASA output files paths
path<-"C:/Thesis_fortran/WASA"
reservoirs$file_WASA<-paste0(path,"/Output/res_",reservoirs$SubbasinID,"_watbal.out")

#Create an index for WASA output files
output<-list.files(path = paste0(path,"/Output"),full.names = T,recursive = TRUE)
#View(output)

#Check if some reservoir is missing from WASA output files
check<-length(reservoirs$file_WASA)-length(output[which(output %in% reservoirs$file_WASA)])
if(check > 0){
  print(reservoirs$Reservoir_name[which(!(reservoirs$file_WASA %in% output))])
  print("The reservoirs above are missing from WASA's output files")
  not_present<-which(!(reservoirs$file_WASA %in% output))
}
#Morada Nova and Umari reservoirs are missing from WASA's output files

#Order the file list and names by the SubbasinID
reservoirs<-reservoirs[order(reservoirs$SubbasinID),]
row.names(reservoirs)<-NULL

#Create a list containing the WASA output files
tic("Import WASA reservoir output files")
position<-c(0,7,13,19,25,35,45,55,68,81,91,101,111,121,131,141,155,169)
widths<-diff(position)
columns<-c("Subasin-ID", "year", "day", "hour", "qlateral(m**3/s)", "transposition(m**3/s)", "inflow(m**3/s)", "evap(m**3)", "prec(m**3)", "intake(m**3/s)", "overflow(m**3/s)", "qbottom(m**3/s)", "qout(m**3/s)", "withdrawal(m**3/s)", "elevation(m)", "area(m**2)", "volume(m**3)")

#Create a dataframe with dates in the rows and volumes in the columns
tic("Import WASA reservoir output volumes")
WASA_volumes<-data.frame(date)
for(i in 1:nrow(reservoirs)){
  if(!(i %in% not_present)){
    name<-paste0("res_",reservoirs$SubbasinID[i])
    res<-read.fwf(reservoirs$file_WASA[i], widths = widths, skip = 3)
    names(res)<-columns
    res$time<-time_index(res)
    
    WASA_volumes$new<-NA
    WASA_volumes$new[which(WASA_volumes$date %in% res$time)]<-
      res$`volume(m**3)`[which(res$time %in% WASA_volumes$date)]
    # WASA_volumes$new<-sistemadati_DCA(vettore = res, lung = length(date),
    #                    g = date, coldata = 17, coltime = 18)[,2]
    names(WASA_volumes)[names(WASA_volumes) == "new"]<-name
  }
}
toc() #105 sec

```

```{r reservoirs observation dataframe}
path<-"C:/Users/Utente/OneDrive - Politecnico di Milano/Backup PC/Uni/Thesis/Data/volume_series_banabuiu_reservoirs_ID"

obs<-data.frame(list.files(path = path, full.names = T, recursive = TRUE))
names(obs)<-"path"
obs$SubbasinID<-gsub("\\..*","",basename(obs$path))

reservoirs$file_OBS<-NA
reservoirs$file_OBS[which(reservoirs$SubbasinID %in% obs$SubbasinID)] <- obs$path

#Create a dataframe with dates in the rows and volumes in the columns
tic("Import volumes from reservoir observations")
OBS_volumes<-data.frame(date)
for(i in 1:nrow(reservoirs)){
  if(!is.na(reservoirs$file_OBS[i])){
  #if(!(i %in% not_present)){
    name<-paste0("res_",reservoirs$SubbasinID[i])
    res<-read.csv(reservoirs$file_OBS[i], header = TRUE, sep = ",")
    res$date<-as.Date(res$date, format = "%Y-%m-%d")

    OBS_volumes$new<-NA
    OBS_volumes$new[which(OBS_volumes$date %in% res$date)]<-
      res$volume[which(res$date %in% OBS_volumes$date)]
    # 0.31 sec
    # modificare sistemadati in modo che sia ancora piÃ¹ efficiente
    
    # OBS_volumes$new<-sistemadati_DCA(vettore = res, lung = length(date),
    #                    g = date, coldata = 2, coltime = 1)[,2]
    # 28.15 sec
    names(OBS_volumes)[names(OBS_volumes) == "new"]<-name
  }
}
toc()

#Export as a .txt

```

```{r monthly volumes}
#Sum the volumes to obtain monthly volumes
month_OBS_volumes<-obt_monthly_values(OBS_volumes)
names(month_OBS_volumes)[names(month_OBS_volumes) == "total"]<-"Banabuiu"

month_WASA_volumes<-obt_monthly_values(WASA_volumes)
names(month_OBS_volumes)[names(month_OBS_volumes) == "total"]<-"Banabuiu"
```

### Test

For each reservoir, check if the volume has been higher than half of the total capacity for at least 50% of the time.
Considering the series until 2020, the test is not passed by the majority of the reservoirs, meaning that for more than 50% of the time its volumes have been under the half of the storage capacity. Since from 2010 an exceptional drought started, these years have been excluded from the second test. In this case, the majority of reservoirs passes the test, meaning that in the period outside the exceptional drought the reservoirs reached the half of their total capacity for at least the 50% of the time. The reservoirs which don't pass this second test didn't reach this threshold, which could mean that their storage capacity is oversized with respect of the actual volume available, or that for management reasons the water have been dispatched in other reservoirs during the years. In any case, for these reservoirs, the deviation from the median is a more feasible indicator to determine the condition of the reservoir, as it represents the value dividing the sample in two halves with 50% probability of occurrence.

Median: computed until 2010, used for the whole series!

The median could not be the best indicator for the VD, because it implies that half of the time the reservoir is in a dry condition and half of the time it is in a wet condition. The mean could be a better indicator then, considering not the 50% probability value, but a 

```{r test_VD}
test_VD = function (volumes, IDs, years, thresholds, lubryear){
  test = data.frame(matrix (NA, ncol(volumes)-1, 5))
  names (test) = c("SubbasinID", "perc_2020", "test_passed_2020", "perc_2010", "test_passed_2010")

  for(i in 1:(ncol(volumes)-1)){
  volume = volumes[which(lubryear >= years[i]+3), i+1]

  test$SubbasinID[i] = IDs[i]
  test$perc_2020[i] = sum(volume > thresholds[i]/2, na.rm = TRUE)/sum(!is.na(volume))
  test$test_passed_2020[i] = ifelse(test$perc_2020[i]>=0.5, "YES", "NO")

  volume = volumes[which(lubryear >= years[i]+3 & lubryear <= 2010), i+1]

  test$perc_2010[i] = sum(volume > thresholds[i]/2, na.rm = TRUE)/sum(!is.na(volume))
  test$test_passed_2010[i] = ifelse(test$perc_2010[i]>=0.5, "YES", "NO")
  }
  test
}

#Max capacities
path<-"C:/Users/Utente/OneDrive - Politecnico di Milano/Backup PC/Uni/Thesis/Analysis/new_reservoirs"
max_cap<-read.table(paste0(path,"/reservoir_toupdate.dat"), skip = 2, sep = "\t")
max_cap<-data.frame(max_cap[,1],max_cap[,9],max_cap[,5]*1000)
names(max_cap)<-c("SubbasinID","year","capacity")

year<-lubridate::year(OBS_volumes[,1])

test = test_VD(OBS_volumes, max_cap$SubbasinID, max_cap$year, max_cap$capacity, year)
View(test)

path<-"C:/Users/Utente/OneDrive - Politecnico di Milano/Backup PC/Uni/Thesis/Analysis/drought_cycle_analysis"
write.table(test, paste0(path, "/test_VD.txt"),sep = "\t", quote = FALSE, row.names = FALSE)
```


### VD computation

```{r VD computation method 1}
#Considering the biggest reservoir in the region
max(apply(month_OBS_volumes[,3:(ncol(month_OBS_volumes)-1)],2,max,na.rm = TRUE))
# Maximum daily volume registered: 1531156000, by Acude Arrojado Lisboa, SubbasinID 156
# Maximum monthly volume registered: 46728798000, by Acude Arrojado Lisboa, SubbasinID 156

#Take the median of the observed volumes of this reservoir
VD_median <- median(month_OBS_volumes$res_156, na.rm = TRUE)

#By considering only this reservoir's variation
VD_v1<-data.frame(month_OBS_volumes$year, month_OBS_volumes$month)
names(VD_v1)<-c("year","month")
VD_v1$VD <-  month_OBS_volumes$res_156 - VD_median

#Standardize
# VD_v1$VD <- (VD_v1$VD - mean(VD_v1$VD, na.rm = TRUE))/sd(VD_v1$VD, na.rm = TRUE)

#Normalize between -1 and 1
VD_v1$VD <- 2*(VD_v1$VD - min(VD_v1$VD, na.rm = TRUE))/
            (max(VD_v1$VD, na.rm = TRUE)-min(VD_v1$VD, na.rm = TRUE)) - 1

# min(VD_v1,na.rm = TRUE)
# View(VD_v1)
```

```{r VD computation method 2}
#Each reservoir is associated with a VD considering its own median
VD_median2 <- apply(month_OBS_volumes[,3:(ncol(month_OBS_volumes)-1)],2,median,na.rm = TRUE)
VD_v2 <- month_OBS_volumes[,3:(ncol(month_OBS_volumes)-1)]
#Normalize between -1 and 1
for(i in 1:ncol(VD_v2)){
  VD_v2[,i]<-VD_v2[,i] - median(VD_v2[,i],na.rm = TRUE)
  VD_v2[,i]<-2*(VD_v2[,i] - min(VD_v2[,i], na.rm = TRUE))/
            (max(VD_v2[,i], na.rm = TRUE) - min(VD_v2[,i], na.rm = TRUE)) - 1
}
#Take the mean for each month to obtain a single index
VD_v2$VD <- apply(VD_v2,1,mean,na.rm = TRUE)

#Add years and months
VD_v2$year<-month_OBS_volumes$year
VD_v2$month<-month_OBS_volumes$month
```

```{r VD Germano formula}

VD_v3<-data.frame(month_OBS_volumes$year, month_OBS_volumes$month)
names(VD_v3)<-c("year","month")
VD_v3$VD <- (month_OBS_volumes$res_156 - VD_median)/VD_median


#VD_v3$VD <- 2*(month_OBS_volumes$res_156 - min(month_OBS_volumes$res_156, na.rm = TRUE))/
#            (max(month_OBS_volumes$res_156, na.rm = TRUE)-min(month_OBS_volumes$res_156, na.rm = TRUE)) - 1

```

```{r plot the VDs}
VD_v1$ID<-"Normalized median - Arrojado Lisboa"
VD_v3$ID<-"Standardized median - Arrojado Lisboa (Germano formula)"
VD_v2$ID<-"Normalized median - Mean of all the reservoirs"

visual <- rbind(VD_v1,VD_v3)
vv<-data.frame(VD_v2$year,VD_v2$month,VD_v2$VD,VD_v2$ID)
names(vv)<-c("year","month","VD","ID")
visual <- rbind(visual,vv)
visual$date<-zoo::as.yearmon(paste(visual$year, visual$month), "%Y %m")
visual %>%
  ggplot( aes(x=date, y=VD, group=ID, color=ID)) +
    geom_line()
```

## Quadrant attribution

1 -	Wet quadrant (non-occurrence of drought):   PI > 0		WSI > 0
2 -	Meteorological drought:                     PI < 0		WSI > 0
3 -	Hydro-meteorological drought:               PI < 0		WSI < 0
4 -	Hydrological drought:                       PI > 0		WSI < 0

```{r quadrant attribution VD1}
#SPI Banabuiu
# list_spi[["SPI12_Banabuiu"]][["fitted"]]

#VD Banabuiu (only res_156 considered)
# VD_v1$VD

DCA<-data.frame(VD_v1, list_spi[["SPI12_Banabuiu"]][["fitted"]])
names(DCA)<-c("year","month","VD","SPI")

DCA$quadrant<-0
for(i in 1:nrow(DCA)){
  if(!is.na(DCA$SPI[i]) & !is.na(DCA$VD[i])){
  if(DCA$SPI[i] > 0 & DCA$VD[i] > 0) DCA$quadrant[i]<-1
  else if(DCA$SPI[i] < 0 & DCA$VD[i] > 0) DCA$quadrant[i]<-2
  else if(DCA$SPI[i] < 0 & DCA$VD[i] < 0) DCA$quadrant[i]<-3
  else if(DCA$SPI[i] > 0 & DCA$VD[i] < 0) DCA$quadrant[i]<-4
}}

plot(DCA$quadrant, type = 'p', main = "DCA with VD method 1")
```

```{r quadrant attribution VD2}
DCA<-data.frame(VD_v2$year, VD_v2$month, VD_v2$VD, list_spi[["SPI12_Banabuiu"]][["fitted"]])
names(DCA)<-c("year","month","VD","SPI")

DCA$quadrant<-0
for(i in 1:nrow(DCA)){
  if(!is.na(DCA$SPI[i]) & !is.na(DCA$VD[i])){
  if(DCA$SPI[i] > 0 & DCA$VD[i] > 0) DCA$quadrant[i]<-1
  else if(DCA$SPI[i] < 0 & DCA$VD[i] > 0) DCA$quadrant[i]<-2
  else if(DCA$SPI[i] < 0 & DCA$VD[i] < 0) DCA$quadrant[i]<-3
  else if(DCA$SPI[i] > 0 & DCA$VD[i] < 0) DCA$quadrant[i]<-4
}}

plot(DCA$quadrant, type = 'p', main = "DCA with VD method 2")
```

